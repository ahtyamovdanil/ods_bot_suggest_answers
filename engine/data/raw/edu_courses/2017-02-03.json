[
    {
        "type": "message",
        "subtype": "channel_join",
        "ts": "1486112342.001694",
        "user": "U40HTBSQ4",
        "text": "<@U40HTBSQ4> has joined the channel"
    },
    {
        "type": "message",
        "subtype": "channel_join",
        "ts": "1486122311.001695",
        "user": "U417TSFE2",
        "text": "<@U417TSFE2> has joined the channel"
    },
    {
        "type": "message",
        "text": "Друзья, вопрос, который наверное сто раз уже обсуждался (хотя поиском по теме ничего не нашел). Хочу прокачаться в нейронках (для машинного зрения, в основном), но не встречал толковых MOOC, прочитал книжку Нильсена - про свёртки там самые основы. С ходу читать статьи по темам довольно tyazhelovato. Есть какие-то курсы-туториалы-обзоры, чтобы по порядочку про cnn, fcn, ...?",
        "user": "U3S96B5QF",
        "ts": "1486128124.001696",
        "team": "T040HKJE3",
        "user_team": "T040HKJE3",
        "source_team": "T040HKJE3",
        "user_profile": {
            "avatar_hash": "f6464b75b7fd",
            "image_72": "https:\/\/avatars.slack-edge.com\/2020-02-16\/956434282631_f6464b75b7fdff296421_72.jpg",
            "first_name": "Daniil",
            "real_name": "Daniil Lysukhin",
            "display_name": "lysukhin",
            "team": "T040HKJE3",
            "name": "lysukhin",
            "is_restricted": false,
            "is_ultra_restricted": false
        }
    },
    {
        "type": "message",
        "text": "cs231n ?",
        "user": "U2M0WG6F2",
        "ts": "1486128199.001697",
        "team": "T040HKJE3",
        "user_team": "T040HKJE3",
        "source_team": "T040HKJE3",
        "user_profile": {
            "avatar_hash": "52924ed31717",
            "image_72": "https:\/\/avatars.slack-edge.com\/2017-03-02\/148772720499_52924ed317177bb1e19c_72.jpg",
            "first_name": "Obednikov",
            "real_name": "Obednikov Alex",
            "display_name": "obednikov.alex",
            "team": "T040HKJE3",
            "name": "obednikov.alex",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "reactions": [
            {
                "name": "heavy_plus_sign",
                "users": [
                    "U2T31R2QJ",
                    "U0M39M6LS",
                    "U1G303UTW",
                    "U09NC5XLN",
                    "U09JEC7V0",
                    "U3S96B5QF",
                    "U1CF22N7J",
                    "U19EZ8L5D",
                    "U1D4RRA7K",
                    "U24FHECDD",
                    "U2PQ7NEDA"
                ],
                "count": 11
            }
        ]
    },
    {
        "type": "message",
        "text": "<http:\/\/cs231n.stanford.edu\/>",
        "user": "U0DJEEXE1",
        "ts": "1486128258.001698",
        "team": "T040HKJE3",
        "user_team": "T040HKJE3",
        "source_team": "T040HKJE3",
        "user_profile": {
            "avatar_hash": "2b518c25d820",
            "image_72": "https:\/\/avatars.slack-edge.com\/2017-01-07\/125252632279_2b518c25d820634753aa_72.png",
            "first_name": "max",
            "real_name": "max ivanov",
            "display_name": "lotek93",
            "team": "T040HKJE3",
            "name": "lotek93",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "reactions": [
            {
                "name": "heavy_plus_sign",
                "users": [
                    "U3S96B5QF",
                    "U24FHECDD",
                    "U2PQ7NEDA"
                ],
                "count": 3
            }
        ]
    },
    {
        "type": "message",
        "text": "принял, спасибо!",
        "user": "U3S96B5QF",
        "ts": "1486128314.001699",
        "team": "T040HKJE3",
        "user_team": "T040HKJE3",
        "source_team": "T040HKJE3",
        "user_profile": {
            "avatar_hash": "f6464b75b7fd",
            "image_72": "https:\/\/avatars.slack-edge.com\/2020-02-16\/956434282631_f6464b75b7fdff296421_72.jpg",
            "first_name": "Daniil",
            "real_name": "Daniil Lysukhin",
            "display_name": "lysukhin",
            "team": "T040HKJE3",
            "name": "lysukhin",
            "is_restricted": false,
            "is_ultra_restricted": false
        }
    },
    {
        "type": "message",
        "subtype": "channel_join",
        "ts": "1486133571.001700",
        "user": "U40N03RGC",
        "text": "<@U40N03RGC> has joined the channel"
    },
    {
        "type": "message",
        "subtype": "channel_join",
        "ts": "1486134888.001701",
        "user": "U41B043NK",
        "text": "<@U41B043NK> has joined the channel"
    },
    {
        "type": "message",
        "subtype": "channel_join",
        "ts": "1486135958.001702",
        "user": "U3ZV1D6U8",
        "text": "<@U3ZV1D6U8> has joined the channel"
    },
    {
        "type": "message",
        "subtype": "channel_join",
        "ts": "1486140994.001703",
        "user": "U41CWED1V",
        "text": "<@U41CWED1V> has joined the channel"
    },
    {
        "type": "message",
        "text": "<@U3S96B5QF> Вот хорошая публикация про основы: <https:\/\/ujjwalkarn.me\/2016\/08\/11\/intuitive-explanation-convnets\/> И ссылки в ней полезные.",
        "user": "U24FHECDD",
        "ts": "1486146490.001704",
        "team": "T040HKJE3",
        "user_team": "T040HKJE3",
        "source_team": "T040HKJE3",
        "user_profile": {
            "avatar_hash": "41a36bd745bd",
            "image_72": "https:\/\/avatars.slack-edge.com\/2016-10-08\/89091959682_41a36bd745bd520397c1_72.jpg",
            "first_name": "Andrey",
            "real_name": "Andrey Ogurtsov",
            "display_name": "statist",
            "team": "T040HKJE3",
            "name": "statist",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "edited": {
            "user": "U24FHECDD",
            "ts": "1486146502.000000"
        },
        "attachments": [
            {
                "service_name": "the data science blog",
                "service_url": "http:\/\/ujjwalkarn.me",
                "title": "An Intuitive Explanation of Convolutional Neural Networks",
                "title_link": "https:\/\/ujjwalkarn.me\/2016\/08\/11\/intuitive-explanation-convnets\/",
                "author_name": "ujjwalkarn",
                "author_link": "https:\/\/ujjwalkarn.me\/author\/ujwlkarn\/",
                "thumb_url": "https:\/\/i2.wp.com\/ujwlkarn.files.wordpress.com\/2016\/08\/screen-shot-2016-08-10-at-12-58-30-pm.png?fit=200%2C150&ssl=1",
                "thumb_width": 142,
                "thumb_height": 150,
                "text": "What are Convolutional Neural Networks and why are they important?\nConvolutional Neural Networks (ConvNets or CNNs) are a category of Neural Networks that have proven very effective&nbsp;in areas such as&nbsp;image recognition and classification. ConvNets have been successful in identifying faces, objects and traffic&nbsp;signs apart from powering vision in robots and self driving cars.\n\nFigure 1: Source [1]\nIn Figure 1 above, a ConvNet is able to recognize scenes and the system is able to suggest relevant tags such as &lsquo;bridge&rsquo;, &lsquo;railway&rsquo; and &lsquo;tennis&rsquo;&nbsp;while Figure 2 shows an example of ConvNets being used for&nbsp;recognizing everyday objects, humans and animals. Lately, ConvNets&nbsp;have been effective in several Natural Language Processing tasks (such as sentence&nbsp;classification) as well.\n\nFigure 2: Source [2]\nConvNets, therefore, are an important tool for most machine learning practitioners today. However, understanding ConvNets and learning to use them for the first time can sometimes be an intimidating experience.&nbsp;The primary purpose of this blog post is to develop an understanding&nbsp;of how Convolutional Neural Networks work on images.\nIf you are new to neural networks in general, I would recommend&nbsp;reading this short&nbsp;tutorial&nbsp;on Multi Layer Perceptrons&nbsp;to get an idea&nbsp;about how they work, before proceeding.&nbsp;Multi Layer Perceptrons&nbsp;are referred to as &ldquo;Fully Connected Layers&rdquo; in this post.\nThe LeNet Architecture (1990s)\nLeNet&nbsp;was one of the very first convolutional neural networks which&nbsp;helped propel the field of Deep Learning. This pioneering work by Yann LeCun was named LeNet5&nbsp;after many previous successful iterations since the year 1988 [3]. At that time the LeNet architecture was used mainly for character recognition tasks such as reading zip codes, digits, etc.\nBelow, we will develop an intuition of how the LeNet architecture learns to recognize images. There have been&nbsp;several new&nbsp;architectures proposed in the recent years which are improvements over the LeNet, but they all&nbsp;use the main concepts from the LeNet and relatively easier to understand if you have a clear understanding of the former.\n\nFigure 3: A simple ConvNet. Source [5]\nThe Convolutional Neural Network in Figure 3&nbsp;is similar in architecture to the original LeNet and classifies an input image into four&nbsp;categories: dog, cat, boat or bird (the original LeNet was used mainly&nbsp;for character recognition tasks). As evident from&nbsp;the figure above, on receiving&nbsp;a boat image as input, the network correctly assigns&nbsp;the highest probability for boat (0.94) among all four&nbsp;categories. The sum of all probabilities in the output layer should be&nbsp;one (explained later in this post).\nThere are four&nbsp;main operations&nbsp;in the&nbsp;ConvNet shown in Figure 3 above:\nConvolution\nNon Linearity (ReLU)\nPooling or Sub Sampling\nClassification (Fully Connected Layer)\nThese operations&nbsp;are the basic building blocks of every&nbsp;Convolutional Neural Network, so understanding how these work is an important step to developing a sound understanding of ConvNets. We will try to understand the intuition behind each of these operations&nbsp;below.\n\nImages are a matrix&nbsp;of pixel values\nEssentially, every image can be represented as a matrix of pixel values.\n\nFigure 4: Every image is a matrix of pixel values. Source [6]\nChannel is a conventional term used to refer to a certain component of an image. An image from a standard digital camera will have three channels &ndash;&nbsp;red, green and blue &ndash; you can imagine those as three&nbsp;2d-matrices stacked over each other (one for each color), each having pixel values in the range 0 to&nbsp;255.\nA&nbsp;grayscale image, on the other hand, has just one channel.&nbsp;For the purpose of this post, we will only consider grayscale images, so we will have a single 2d matrix representing an image. The value of each pixel&nbsp;in the matrix will range from 0 to 255 &ndash; zero&nbsp;indicating black&nbsp;and 255 indicating white.\n\nThe&nbsp;Convolution Step\nConvNets derive their name from the&nbsp;&ldquo;convolution&rdquo; operator. The primary purpose of Convolution in case of a ConvNet is to extract features from the input image.&nbsp;Convolution preserves the spatial relationship between pixels by learning image features using small squares of input data.&nbsp;We will not go into the mathematical details&nbsp;of Convolution here, but will try to understand how it works over images.\nAs we discussed above, every image can be considered as a matrix of pixel values. Consider a 5 x 5 image whose pixel values are only 0 and 1 (note that for a grayscale image, pixel values range from 0 to 255, the green matrix below is a special case where&nbsp;pixel values are only 0 and 1):\n\nAlso, consider another 3 x 3 matrix as shown below:\n\nThen, the Convolution of the 5 x 5 image and the 3 x 3 matrix can be computed as shown in the animation in Figure 5 below:\nFigure 5:&nbsp;The Convolution operation. The output matrix is called Convolved Feature or Feature Map. Source [7]\nTake a moment to understand how the computation above is being done. We&nbsp;slide the orange matrix over our original image (green) by 1 pixel&nbsp;(also called &lsquo;stride&rsquo;) and for every position, we compute element wise multiplication (between the two matrices) and add the multiplication outputs to get the final integer which forms a&nbsp;single element of the output matrix (pink). Note that the 3&times;3 matrix &ldquo;sees&rdquo; only a part of the input image in each stride.\nIn CNN terminology, the 3&times;3 matrix is called a &lsquo;filter&lsquo; or &lsquo;kernel&rsquo; or &lsquo;feature detector&rsquo; and the matrix formed by sliding the filter over the image and computing the dot product is called the &lsquo;Convolved Feature&rsquo; or &lsquo;Activation Map&rsquo; or the &lsquo;Feature Map&lsquo;. It is important to note that filters acts as feature detectors from the original input image.\nIt is evident from the animation above that different values of the filter matrix will produce different Feature&nbsp;Maps for&nbsp;the same input image. As an example, consider the following input image:\n\nIn the table below, we can see the effects of convolution of the above image with&nbsp;different filters. As shown, we can perform operations&nbsp;such as Edge Detection, Sharpen and Blur just by changing the numeric values of our filter matrix before the convolution operation [8] &ndash; this means that different filters can detect different features from an image, for example edges, curves etc. More such examples are available in Section 8.2.4&nbsp;here.\n\nAnother good way to understand the&nbsp;Convolution operation&nbsp;is by looking at the animation in Figure 6&nbsp;below:\n\nFigure 6: The Convolution Operation. Source [9]\nA filter (with red outline) slides&nbsp;over the input&nbsp;image (convolution operation) to produce a feature map. The convolution of another filter (with the green outline), over the same image gives a different feature map as shown. It is important to note that the Convolution operation captures&nbsp;the local dependancies in the original image. Also notice how these two different filters generate&nbsp;different feature&nbsp;maps from the same original image. Remember that the image and the two&nbsp;filters above are just numeric matrices as we have discussed above.\nIn practice, a CNN learns the values of these filters on its own during the training process (although we still need to specify parameters such as number of filters, filter size, architecture of the network etc. before the training process). The more number of filters we&nbsp;have, the more image features get extracted and the better our network becomes at recognizing&nbsp;patterns in unseen images.\nThe size of the Feature Map (Convolved Feature) is cont…",
                "fallback": "the data science blog Link: An Intuitive Explanation of Convolutional Neural&nbsp;Networks",
                "from_url": "https:\/\/ujjwalkarn.me\/2016\/08\/11\/intuitive-explanation-convnets\/",
                "service_icon": "https:\/\/secure.gravatar.com\/blavatar\/dd6b43bdba2d70c3cba3c003f283ec50?s=114",
                "id": 1
            }
        ],
        "reactions": [
            {
                "name": "+1",
                "users": [
                    "U1LJE9MCK",
                    "U3S96B5QF",
                    "U3U0AKQ0Y",
                    "U3P28DQ5T",
                    "U31S67ZC5"
                ],
                "count": 5
            }
        ]
    },
    {
        "type": "message",
        "subtype": "channel_join",
        "ts": "1486151008.001707",
        "user": "U41FU6GUX",
        "text": "<@U41FU6GUX> has joined the channel"
    },
    {
        "type": "message",
        "subtype": "channel_join",
        "ts": "1486190783.001708",
        "user": "U41LBNH6J",
        "text": "<@U41LBNH6J> has joined the channel"
    }
]